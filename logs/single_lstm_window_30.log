Using device: cuda
Train input shape: (4017, 12)
Validation input shape: (4018, 12)
Test input shape: (365, 12)
Training with window_size=30
Check the shapes of the generated sequences
-----------------------------------------
Train input shape: torch.Size([3988, 30, 12])
Train target shape: torch.Size([3988, 65341, 1])
Validation input shape: torch.Size([3989, 30, 12])
Validation target shape: torch.Size([3989, 65341, 1])
Test input shape: torch.Size([336, 30, 12])
Test target shape: torch.Size([336, 65341, 1])
-----------------------------------------
Create DataLoaders for training and validation sets
-----------------------------------------
Batch size: 16
SequentialDeepONet(
  (branch_net): LSTM(
    (lstm): LSTM(12, 128, num_layers=4, batch_first=True)
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (trunk_net): FCN(
    (network): Sequential(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
    )
  )
)
Set the hyperparameters
-----------------------------------------
single_branch/lstm_window_30_1.pth
Number of epochs: 1000
Learning rate: 0.001
Patience: 10
Loss function: MSELoss()
-----------------------------------------
Epoch 1/1000, Train Loss: 0.204508, Validation Loss: 0.000569
Epoch 2/1000, Train Loss: 0.001370, Validation Loss: 0.001939
Epoch 3/1000, Train Loss: 0.001241, Validation Loss: 0.000290
Epoch 4/1000, Train Loss: 0.001109, Validation Loss: 0.000253
Epoch 5/1000, Train Loss: 0.001038, Validation Loss: 0.000554
Epoch 6/1000, Train Loss: 0.001009, Validation Loss: 0.000239
Epoch 7/1000, Train Loss: 0.000875, Validation Loss: 0.000208
Epoch 8/1000, Train Loss: 0.000898, Validation Loss: 0.000198
Epoch 9/1000, Train Loss: 0.000734, Validation Loss: 0.000975
Epoch 10/1000, Train Loss: 0.000621, Validation Loss: 0.000122
Epoch 11/1000, Train Loss: 0.000732, Validation Loss: 0.000269
Epoch 12/1000, Train Loss: 0.000483, Validation Loss: 0.000596
Epoch 13/1000, Train Loss: 0.000321, Validation Loss: 0.000131
Epoch 14/1000, Train Loss: 0.000284, Validation Loss: 0.000060
Epoch 15/1000, Train Loss: 0.000121, Validation Loss: 0.000035
Epoch 16/1000, Train Loss: 0.000120, Validation Loss: 0.000031
Epoch 17/1000, Train Loss: 0.000121, Validation Loss: 0.000059
Epoch 18/1000, Train Loss: 0.000136, Validation Loss: 0.000027
Epoch 19/1000, Train Loss: 0.000133, Validation Loss: 0.000091
Epoch 20/1000, Train Loss: 0.000149, Validation Loss: 0.000074
Epoch 21/1000, Train Loss: 0.000223, Validation Loss: 0.000065
Epoch 22/1000, Train Loss: 0.000193, Validation Loss: 0.000033
Epoch 23/1000, Train Loss: 0.000201, Validation Loss: 0.000012
Epoch 24/1000, Train Loss: 0.000222, Validation Loss: 0.000012
Epoch 25/1000, Train Loss: 0.000181, Validation Loss: 0.000024
Epoch 26/1000, Train Loss: 0.000096, Validation Loss: 0.000011
Epoch 27/1000, Train Loss: 0.000262, Validation Loss: 0.000719
Epoch 28/1000, Train Loss: 0.000161, Validation Loss: 0.000022
Epoch 29/1000, Train Loss: 0.000064, Validation Loss: 0.000028
Epoch 30/1000, Train Loss: 0.000121, Validation Loss: 0.000030
Epoch 31/1000, Train Loss: 0.000370, Validation Loss: 0.000076
Epoch 32/1000, Train Loss: 0.000081, Validation Loss: 0.000028
Epoch 33/1000, Train Loss: 0.000048, Validation Loss: 0.000011
Epoch 34/1000, Train Loss: 0.000054, Validation Loss: 0.000249
Epoch 35/1000, Train Loss: 0.000093, Validation Loss: 0.000039
Epoch 36/1000, Train Loss: 0.000075, Validation Loss: 0.000111
Early stopping at epoch 36
Training completed!
All predictions shape before reshape: (336, 65341, 1)
All targets shape before reshape: (336, 65341, 1)
All predictions shape after reshape: (336, 65341)
All targets shape after reshape: (336, 65341)
Predictions and targets saved to single_branch/array/lstm_window_30_preds_targets_1.npy
Results saved to single_branch/array/lstm_window_30_results_1.npy
Final Model Evaluation on Test Set:
RMSE: 0.0000, MAE: 0.0000, RÂ²: 0.9998, L2 Error: 0.0094
(3.6930218e-05, 3.0110728e-05, 0.9998169547448664, 0.00944006)
