Using device: cuda
Train input shape: (4017, 12)
Validation input shape: (4018, 12)
Test input shape: (365, 12)
Training with window_size=90
Check the shapes of the generated sequences
-----------------------------------------
Train input shape: torch.Size([3928, 90, 12])
Train target shape: torch.Size([3928, 65341, 1])
Validation input shape: torch.Size([3929, 90, 12])
Validation target shape: torch.Size([3929, 65341, 1])
Test input shape: torch.Size([276, 90, 12])
Test target shape: torch.Size([276, 65341, 1])
-----------------------------------------
Create DataLoaders for training and validation sets
-----------------------------------------
Batch size: 16
Set the hyperparameters
-----------------------------------------
multi_branch/lstm_window_90.pth
Number of epochs: 1000
Learning rate: 0.001
Patience: 10
Loss function: MSELoss()
-----------------------------------------
Epoch 1/1000, Train Loss: 6476.856435, Val Loss: 0.180012
Epoch 2/1000, Train Loss: 0.072182, Val Loss: 0.024634
Epoch 3/1000, Train Loss: 0.035932, Val Loss: 0.020573
Epoch 4/1000, Train Loss: 0.025562, Val Loss: 0.014745
Epoch 5/1000, Train Loss: 0.022996, Val Loss: 0.011631
Epoch 6/1000, Train Loss: 0.021916, Val Loss: 0.007681
Epoch 7/1000, Train Loss: 0.025472, Val Loss: 0.016229
Epoch 8/1000, Train Loss: 0.026529, Val Loss: 0.008942
Epoch 9/1000, Train Loss: 0.017549, Val Loss: 0.021945
Epoch 10/1000, Train Loss: 0.013400, Val Loss: 0.005889
Epoch 11/1000, Train Loss: 0.022673, Val Loss: 0.004844
Epoch 12/1000, Train Loss: 0.016754, Val Loss: 0.006182
Epoch 13/1000, Train Loss: 0.011011, Val Loss: 0.004658
Epoch 14/1000, Train Loss: 0.029727, Val Loss: 0.003885
Epoch 15/1000, Train Loss: 0.007867, Val Loss: 0.003509
Epoch 16/1000, Train Loss: 0.006888, Val Loss: 0.003913
Epoch 17/1000, Train Loss: 0.009008, Val Loss: 0.028766
Epoch 18/1000, Train Loss: 0.026448, Val Loss: 0.002973
Epoch 19/1000, Train Loss: 0.006934, Val Loss: 0.017121
Epoch 20/1000, Train Loss: 0.005980, Val Loss: 0.002814
Epoch 21/1000, Train Loss: 0.006214, Val Loss: 0.005387
Epoch 22/1000, Train Loss: 0.022110, Val Loss: 0.014304
Epoch 23/1000, Train Loss: 0.005007, Val Loss: 0.003914
Epoch 24/1000, Train Loss: 0.005654, Val Loss: 0.004851
Epoch 25/1000, Train Loss: 0.006900, Val Loss: 0.016650
Epoch 26/1000, Train Loss: 0.006498, Val Loss: 0.006115
Epoch 27/1000, Train Loss: 0.005509, Val Loss: 0.005572
Epoch 28/1000, Train Loss: 0.005959, Val Loss: 0.002178
Epoch 29/1000, Train Loss: 0.005708, Val Loss: 0.005914
Epoch 30/1000, Train Loss: 0.007031, Val Loss: 0.005226
Epoch 31/1000, Train Loss: 0.005914, Val Loss: 0.001828
Epoch 32/1000, Train Loss: 0.005568, Val Loss: 0.002034
Epoch 33/1000, Train Loss: 0.004969, Val Loss: 0.001304
Epoch 34/1000, Train Loss: 0.005139, Val Loss: 0.007731
Epoch 35/1000, Train Loss: 0.004318, Val Loss: 0.002379
Epoch 36/1000, Train Loss: 0.004258, Val Loss: 0.001635
Epoch 37/1000, Train Loss: 0.003959, Val Loss: 0.002823
Epoch 38/1000, Train Loss: 0.003708, Val Loss: 0.003075
Epoch 39/1000, Train Loss: 0.003875, Val Loss: 0.003032
Epoch 40/1000, Train Loss: 0.003757, Val Loss: 0.001867
Epoch 41/1000, Train Loss: 0.003311, Val Loss: 0.001068
Epoch 42/1000, Train Loss: 0.003577, Val Loss: 0.002475
Epoch 43/1000, Train Loss: 0.003961, Val Loss: 0.001390
Epoch 44/1000, Train Loss: 0.003256, Val Loss: 0.001483
Epoch 45/1000, Train Loss: 0.002657, Val Loss: 0.003688
Epoch 46/1000, Train Loss: 0.002846, Val Loss: 0.001839
Epoch 47/1000, Train Loss: 0.002513, Val Loss: 0.003491
Epoch 48/1000, Train Loss: 0.002306, Val Loss: 0.000948
Epoch 49/1000, Train Loss: 0.002075, Val Loss: 0.005330
Epoch 50/1000, Train Loss: 0.002120, Val Loss: 0.001212
Epoch 51/1000, Train Loss: 0.002182, Val Loss: 0.001078
Epoch 52/1000, Train Loss: 0.002314, Val Loss: 0.000877
Epoch 53/1000, Train Loss: 0.002163, Val Loss: 0.002270
Epoch 54/1000, Train Loss: 0.001969, Val Loss: 0.002991
Epoch 55/1000, Train Loss: 0.001895, Val Loss: 0.001834
Epoch 56/1000, Train Loss: 0.001724, Val Loss: 0.002201
Epoch 57/1000, Train Loss: 0.001826, Val Loss: 0.000441
Epoch 58/1000, Train Loss: 0.001857, Val Loss: 0.000474
Epoch 59/1000, Train Loss: 0.001687, Val Loss: 0.001150
Epoch 60/1000, Train Loss: 0.001773, Val Loss: 0.002478
Epoch 61/1000, Train Loss: 0.001661, Val Loss: 0.000936
Epoch 62/1000, Train Loss: 0.002043, Val Loss: 0.000661
Epoch 63/1000, Train Loss: 0.001749, Val Loss: 0.000390
Epoch 64/1000, Train Loss: 0.001679, Val Loss: 0.000489
Epoch 65/1000, Train Loss: 0.001605, Val Loss: 0.000393
Epoch 66/1000, Train Loss: 0.001796, Val Loss: 0.001153
Epoch 67/1000, Train Loss: 0.001651, Val Loss: 0.000794
Epoch 68/1000, Train Loss: 0.002024, Val Loss: 0.000348
Epoch 69/1000, Train Loss: 0.001653, Val Loss: 0.000689
Epoch 70/1000, Train Loss: 0.001834, Val Loss: 0.000419
Epoch 71/1000, Train Loss: 0.001908, Val Loss: 0.000451
Epoch 72/1000, Train Loss: 0.001661, Val Loss: 0.000476
Epoch 73/1000, Train Loss: 0.001699, Val Loss: 0.000408
Epoch 74/1000, Train Loss: 0.001611, Val Loss: 0.001119
Epoch 75/1000, Train Loss: 0.001796, Val Loss: 0.001334
Epoch 76/1000, Train Loss: 0.002231, Val Loss: 0.001815
Epoch 77/1000, Train Loss: 0.001789, Val Loss: 0.000851
Epoch 78/1000, Train Loss: 0.001977, Val Loss: 0.002006
Early stopping
Training completed
All predictions shape before reshape: (276, 65341, 1)
All targets shape before reshape: (276, 65341, 1)
All predictions shape after reshape: (276, 65341)
All targets shape after reshape: (276, 65341)
Predictions and targets saved to multi_branch/array/lstm_window_90_preds_targets.npy
Results saved to multi_branch/array/lstm_window_90_results.npy
Final Model Evaluation on Test Set:
RMSE: 0.0003, MAE: 0.0003, RÂ²: 0.9816, L2 Error: 0.0765
(0.00029908805, 0.0002630907, 0.9815862175733934, 0.07645254)
