Using device: cuda
Train input shape: (4017, 12)
Validation input shape: (4018, 12)
Test input shape: (365, 12)
Training with window_size=7
Check the shapes of the generated sequences
-----------------------------------------
Train input shape: torch.Size([4011, 7, 12])
Train target shape: torch.Size([4011, 65341, 1])
Validation input shape: torch.Size([4012, 7, 12])
Validation target shape: torch.Size([4012, 65341, 1])
Test input shape: torch.Size([359, 7, 12])
Test target shape: torch.Size([359, 65341, 1])
-----------------------------------------
Create DataLoaders for training and validation sets
-----------------------------------------
Batch size: 16
Set the hyperparameters
-----------------------------------------
multi_branch/lstm_window_7.pth
Number of epochs: 1000
Learning rate: 0.001
Patience: 10
Loss function: MSELoss()
-----------------------------------------
Epoch 1/1000, Train Loss: 1257.099605, Val Loss: 0.040410
Epoch 2/1000, Train Loss: 0.029310, Val Loss: 0.018919
Epoch 3/1000, Train Loss: 0.019190, Val Loss: 0.007965
Epoch 4/1000, Train Loss: 0.016650, Val Loss: 0.010048
Epoch 5/1000, Train Loss: 0.014198, Val Loss: 0.019628
Epoch 6/1000, Train Loss: 0.015185, Val Loss: 0.018524
Epoch 7/1000, Train Loss: 0.010958, Val Loss: 0.006701
Epoch 8/1000, Train Loss: 0.012303, Val Loss: 0.005379
Epoch 9/1000, Train Loss: 0.011803, Val Loss: 0.003373
Epoch 10/1000, Train Loss: 0.008902, Val Loss: 0.006287
Epoch 11/1000, Train Loss: 0.007255, Val Loss: 0.004185
Epoch 12/1000, Train Loss: 0.006801, Val Loss: 0.009267
Epoch 13/1000, Train Loss: 0.005618, Val Loss: 0.002225
Epoch 14/1000, Train Loss: 0.004955, Val Loss: 0.001826
Epoch 15/1000, Train Loss: 0.004797, Val Loss: 0.001309
Epoch 16/1000, Train Loss: 0.005370, Val Loss: 0.002597
Epoch 17/1000, Train Loss: 0.004145, Val Loss: 0.001168
Epoch 18/1000, Train Loss: 0.003998, Val Loss: 0.001887
Epoch 19/1000, Train Loss: 0.004483, Val Loss: 0.001309
Epoch 20/1000, Train Loss: 0.004959, Val Loss: 0.003650
Epoch 21/1000, Train Loss: 0.004799, Val Loss: 0.001364
Epoch 22/1000, Train Loss: 0.004525, Val Loss: 0.000946
Epoch 23/1000, Train Loss: 0.003316, Val Loss: 0.002690
Epoch 24/1000, Train Loss: 0.004896, Val Loss: 0.003368
Epoch 25/1000, Train Loss: 0.005001, Val Loss: 0.008039
Epoch 26/1000, Train Loss: 0.003376, Val Loss: 0.000939
Epoch 27/1000, Train Loss: 0.003034, Val Loss: 0.001260
Epoch 28/1000, Train Loss: 0.003960, Val Loss: 0.002503
Epoch 29/1000, Train Loss: 0.003365, Val Loss: 0.001109
Epoch 30/1000, Train Loss: 0.003308, Val Loss: 0.002924
Epoch 31/1000, Train Loss: 0.004382, Val Loss: 0.003596
Epoch 32/1000, Train Loss: 3.137304, Val Loss: 0.703020
Epoch 33/1000, Train Loss: 31.350642, Val Loss: 0.013270
Epoch 34/1000, Train Loss: 0.014331, Val Loss: 0.005467
Epoch 35/1000, Train Loss: 0.013475, Val Loss: 0.007998
Epoch 36/1000, Train Loss: 0.012472, Val Loss: 0.004769
Early stopping
Training completed
All predictions shape before reshape: (359, 65341, 1)
All targets shape before reshape: (359, 65341, 1)
All predictions shape after reshape: (359, 65341)
All targets shape after reshape: (359, 65341)
Predictions and targets saved to multi_branch/array/lstm_window_7_preds_targets.npy
Results saved to multi_branch/array/lstm_window_7_results.npy
Final Model Evaluation on Test Set:
RMSE: 0.0003, MAE: 0.0003, RÂ²: 0.9864, L2 Error: 0.0775
(0.000303132, 0.00025478704, 0.9863796395289876, 0.077486254)
