Using device: cuda
Train input shape: (4017, 12)
Validation input shape: (4018, 12)
Test input shape: (365, 12)
Training with window_size=7
Check the shapes of the generated sequences
-----------------------------------------
Train input shape: torch.Size([4011, 7, 12])
Train target shape: torch.Size([4011, 65341, 1])
Validation input shape: torch.Size([4012, 7, 12])
Validation target shape: torch.Size([4012, 65341, 1])
Test input shape: torch.Size([359, 7, 12])
Test target shape: torch.Size([359, 65341, 1])
-----------------------------------------
Create DataLoaders for training and validation sets
-----------------------------------------
Batch size: 16
SequentialDeepONet(
  (branch_net): GRU(
    (gru): GRU(12, 128, num_layers=4, batch_first=True)
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (fc): Linear(in_features=128, out_features=128, bias=True)
  )
  (trunk_net): FCN(
    (network): Sequential(
      (0): Linear(in_features=2, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
    )
  )
  (final_layer): Linear(in_features=128, out_features=1, bias=True)
)
Set the hyperparameters
-----------------------------------------
single_branch/gru_window_7.pth
Number of epochs: 1000
Learning rate: 0.001
Patience: 10
Loss function: MSELoss()
-----------------------------------------
Epoch 1/1000, Train Loss: 0.012944, Validation Loss: 0.000568
Epoch 2/1000, Train Loss: 0.001024, Validation Loss: 0.000142
Epoch 3/1000, Train Loss: 0.000324, Validation Loss: 0.000058
Epoch 4/1000, Train Loss: 0.000147, Validation Loss: 0.000027
Epoch 5/1000, Train Loss: 0.000055, Validation Loss: 0.000012
Epoch 6/1000, Train Loss: 0.000085, Validation Loss: 0.000187
Epoch 7/1000, Train Loss: 0.000129, Validation Loss: 0.000021
Epoch 8/1000, Train Loss: 0.000074, Validation Loss: 0.000433
Epoch 9/1000, Train Loss: 0.000124, Validation Loss: 0.000071
Epoch 10/1000, Train Loss: 0.000100, Validation Loss: 0.000024
Epoch 11/1000, Train Loss: 0.000055, Validation Loss: 0.000015
Epoch 12/1000, Train Loss: 0.000153, Validation Loss: 0.000024
Epoch 13/1000, Train Loss: 0.000074, Validation Loss: 0.000012
Epoch 14/1000, Train Loss: 0.000091, Validation Loss: 0.000042
Epoch 15/1000, Train Loss: 0.000063, Validation Loss: 0.000103
Epoch 16/1000, Train Loss: 0.000088, Validation Loss: 0.000045
Epoch 17/1000, Train Loss: 0.000131, Validation Loss: 0.000017
Epoch 18/1000, Train Loss: 0.000126, Validation Loss: 0.000508
Epoch 19/1000, Train Loss: 0.000118, Validation Loss: 0.000024
Epoch 20/1000, Train Loss: 0.000051, Validation Loss: 0.000051
Epoch 21/1000, Train Loss: 0.000111, Validation Loss: 0.000076
Epoch 22/1000, Train Loss: 0.000056, Validation Loss: 0.000009
Epoch 23/1000, Train Loss: 0.000067, Validation Loss: 0.000017
Epoch 24/1000, Train Loss: 0.000058, Validation Loss: 0.000018
Epoch 25/1000, Train Loss: 0.000068, Validation Loss: 0.000007
Epoch 26/1000, Train Loss: 0.000048, Validation Loss: 0.000014
Epoch 27/1000, Train Loss: 0.000034, Validation Loss: 0.000026
Epoch 28/1000, Train Loss: 0.000054, Validation Loss: 0.000052
Epoch 29/1000, Train Loss: 0.000064, Validation Loss: 0.000013
Epoch 30/1000, Train Loss: 0.000137, Validation Loss: 0.000013
Epoch 31/1000, Train Loss: 0.000042, Validation Loss: 0.000056
Epoch 32/1000, Train Loss: 0.000188, Validation Loss: 0.000014
Epoch 33/1000, Train Loss: 0.000119, Validation Loss: 0.000032
Epoch 34/1000, Train Loss: 0.000025, Validation Loss: 0.000011
Epoch 35/1000, Train Loss: 0.000042, Validation Loss: 0.000009
Early stopping at epoch 35
Training completed!
All predictions shape before reshape: (359, 65341, 1)
All targets shape before reshape: (359, 65341, 1)
All predictions shape after reshape: (359, 65341)
All targets shape after reshape: (359, 65341)
Predictions and targets saved to single_branch/array/gru_window_7_preds_targets.npy
Results saved to single_branch/array/gru_window_7_results.npy
Final Model Evaluation on Test Set:
RMSE: 0.0000, MAE: 0.0000, RÂ²: 0.9998, L2 Error: 0.0099
(3.8545008e-05, 3.140532e-05, 0.9997781511988136, 0.009852832)
