{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import create_sliding_windows, SequentialMIONetDataset, SequentialDeepONetDataset\n",
    "from s_mionet import SequentialMIONet\n",
    "from s_deeponet import SequentialDeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_single_model(b_type: str):\n",
    "    dim = 128\n",
    "    model = SequentialDeepONet(\n",
    "        branch_type=b_type,\n",
    "        branch_input_size=12,\n",
    "        branch_hidden_size=128,\n",
    "        branch_num_layers=4,\n",
    "        branch_output_size=dim,\n",
    "        trunk_architecture=[2, 128, 128, dim],\n",
    "        num_outputs=1,\n",
    "        use_transform=True,\n",
    "        activation_fn=nn.ReLU,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_multi_model(b_type: str):\n",
    "    dim = 128\n",
    "\n",
    "    # Define a single branch configuration to be reused\n",
    "    base_branch_config = {\n",
    "        \"type\": b_type,\n",
    "        \"input_size\": 1,\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"output_size\": dim\n",
    "    }\n",
    "\n",
    "    # Create a dictionary with the same branch configuration for 12 branches\n",
    "    branches_config = {f\"sensor{i+1}\": base_branch_config for i in range(12)}\n",
    "\n",
    "    # Trunk network configuration\n",
    "    trunk_architecture = [2, 128, 128, dim]\n",
    "    num_outputs = 1\n",
    "\n",
    "    # Instantiate the model with the replicated branches\n",
    "    model = SequentialMIONet(branches_config, trunk_architecture, num_outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "arch = ['single_branch', 'multi_branch']\n",
    "\n",
    "# branch type\n",
    "b_type = ['lstm', 'gru']\n",
    "\n",
    "# sequence length\n",
    "s_length = [7, 30, 60, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(arch, b_type, s_length, device):\n",
    "    \n",
    "    # condition to load the model\n",
    "    if arch == 'single_branch':\n",
    "        if b_type == 'lstm':\n",
    "            model = init_single_model(b_type).to(device)\n",
    "        else:\n",
    "            model = init_single_model(b_type).to(device)\n",
    "    elif arch == 'multi_branch':\n",
    "        if b_type == 'lstm':\n",
    "            model = init_multi_model(b_type).to(device)\n",
    "        else:\n",
    "            model = init_multi_model(b_type).to(device)\n",
    "    \n",
    "    # set the model parameters path\n",
    "    dir_name = f\"{arch}/{b_type}_window_{s_length}.pth\"\n",
    "    print(f\"Model path: {dir_name}\")\n",
    "    \n",
    "    # load the model\n",
    "    model.load_state_dict(torch.load(dir_name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neutron monitoring data\n",
    "input_data = np.load('data/neutron_data_22yrs.npy')\n",
    "trunk = np.load('data/grid_points.npy')\n",
    "target = np.load('data/dose_array.npy')\n",
    "\n",
    "# Normalize trunk input\n",
    "trunk[:, 0] = (trunk[:, 0] - np.min(trunk[:, 0])) / (np.max(trunk[:, 0]) - np.min(trunk[:, 0]))\n",
    "trunk[:, 1] = (trunk[:, 1] - np.min(trunk[:, 1])) / (np.max(trunk[:, 1]) - np.min(trunk[:, 1]))\n",
    "\n",
    "# %%\n",
    "def train_val_test_split(input_data, target):\n",
    "    # Define the number of test samples (last 365 days)\n",
    "    test_size = 365\n",
    "\n",
    "    # Split data into training+validation and test\n",
    "    train_val_input = input_data[:-test_size]\n",
    "    train_val_target = target[:-test_size]\n",
    "    test_input = input_data[-test_size:]\n",
    "    test_target = target[-test_size:]\n",
    "\n",
    "    # Calculate split index for training and validation\n",
    "    train_size = int(len(train_val_input) * 0.5)  # 80% for training\n",
    "    val_size = len(train_val_input) - train_size  # 20% for validation\n",
    "\n",
    "    # Training set\n",
    "    train_input = train_val_input[:train_size]\n",
    "    train_target = train_val_target[:train_size]\n",
    "\n",
    "    # Validation set\n",
    "    val_input = train_val_input[train_size:]\n",
    "    val_target = train_val_target[train_size:]\n",
    "\n",
    "    # Final shapes check\n",
    "    print(\"Train input shape:\", train_input.shape)\n",
    "    print(\"Validation input shape:\", val_input.shape)\n",
    "    print(\"Test input shape:\", test_input.shape)\n",
    "\n",
    "    return train_input, train_target, val_input, val_target, test_input, test_target\n",
    "\n",
    "# Assuming input_data and target are defined elsewhere in the notebook\n",
    "train_input, train_target, val_input, val_target, test_input, test_target = train_val_test_split(input_data, target)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_input = scaler.fit_transform(train_input)\n",
    "val_input = scaler.transform(val_input)\n",
    "test_input = scaler.transform(test_input)\n",
    "\n",
    "# target data normalization (min-max scaling)\n",
    "scaler_target = MinMaxScaler()\n",
    "train_target = scaler_target.fit_transform(train_target)[..., np.newaxis]\n",
    "val_target = scaler_target.transform(val_target)[..., np.newaxis]\n",
    "test_target = scaler_target.transform(test_target)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(arch, s_length, input_data, trunk_data, target):\n",
    "    # Create sliding windows\n",
    "    test_input_seq, test_target_seq = create_sliding_windows(test_input, test_target, s_length)\n",
    "    print(\"Test input shape:\", test_input_seq.shape)\n",
    "    print(\"Test target shape:\", test_target_seq.shape)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    batch_size = 16\n",
    "    if arch == 'single_branch':\n",
    "        test_dataset = SequentialDeepONetDataset(test_input_seq, trunk, test_target_seq)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        test_dataset = SequentialMIONetDataset(test_input_seq, trunk, test_target_seq)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_time(model, test_loader, arch, warmup_iters=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Warm-up iterations to stabilize GPU performance\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup_iters):\n",
    "            for batch in test_loader:\n",
    "                if arch == 'single_branch':\n",
    "                    x, trunk, y = batch\n",
    "                    x, trunk, y = x.to(device), trunk.to(device), y.to(device)\n",
    "                    _ = model(x, trunk)\n",
    "                else:  # multi_branch case\n",
    "                    branch_batch, trunk_batch, target_batch = batch\n",
    "                    if isinstance(branch_batch, dict):\n",
    "                        branch_batch = {key: value.to(device) for key, value in branch_batch.items()}\n",
    "                    else:\n",
    "                        branch_batch = branch_batch.to(device)\n",
    "                    trunk_batch = trunk_batch.to(device)\n",
    "                    target_batch = target_batch.to(device)\n",
    "                    _ = model(branch_batch, trunk_batch)\n",
    "\n",
    "    # Collect inference times per batch\n",
    "    batch_times = []\n",
    "    sample_counts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch_size = len(batch[0])  # Assuming batch[0] holds the input tensor\n",
    "            sample_counts.append(batch_size)  # Track sample count\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            \n",
    "            if arch == 'single_branch':\n",
    "                x, trunk, y = batch\n",
    "                x, trunk, y = x.to(device), trunk.to(device), y.to(device)\n",
    "                _ = model(x, trunk)\n",
    "            else:\n",
    "                branch_batch, trunk_batch, target_batch = batch\n",
    "                if isinstance(branch_batch, dict):\n",
    "                    branch_batch = {key: value.to(device) for key, value in branch_batch.items()}\n",
    "                else:\n",
    "                    branch_batch = branch_batch.to(device)\n",
    "                trunk_batch = trunk_batch.to(device)\n",
    "                target_batch = target_batch.to(device)\n",
    "                _ = model(branch_batch, trunk_batch)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            batch_times.append(end_time - start_time)\n",
    "\n",
    "    # Compute statistics\n",
    "    total_samples = sum(sample_counts)\n",
    "    mean_time = np.mean(batch_times) / np.mean(sample_counts) if total_samples > 0 else float('inf')\n",
    "    std_time = np.std(batch_times) / np.mean(sample_counts) if total_samples > 0 else float('inf')\n",
    "\n",
    "    # Print results in scientific notation\n",
    "    print(f\"Model: {arch}\")\n",
    "    print(f\"Mean Inference Time per Sample: {mean_time:.3e} Â± {std_time:.3e} seconds/sample\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "# Define the output log file path\n",
    "log_file_path = \"temp/inference_time_log.txt\"\n",
    "\n",
    "# Open the file and redirect print statements\n",
    "with open(log_file_path, \"w\") as f:\n",
    "    sys.stdout = f  # Redirect print statements to file\n",
    "    \n",
    "    # Compute inference time for all models and configurations\n",
    "    for a in arch:\n",
    "        for b in b_type:\n",
    "            for s in s_length:\n",
    "                model = load_model(a, b, s, device).eval()\n",
    "                test_loader = create_sequence(a, s, test_input, trunk, test_target)\n",
    "\n",
    "                # Compute trainable parameters\n",
    "                num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "                print(f\"Model: {a}, Branch type: {b}, Sequence length: {s}\")\n",
    "                print(f\"Trainable Parameters: {num_params:,}\")  # Format with comma separator\n",
    "\n",
    "                compute_time(model, test_loader, a)\n",
    "                print(\"\\n\")\n",
    "\n",
    "# Restore standard output back to normal\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "print(f\"Log saved to {log_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-env]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
