{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908bd9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/kazumak2/.conda/envs/pytorch-env/lib/python3.9/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0e3b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# compactly add project src and analysis/zero-shot to sys.path if not already present\n",
    "for rel in ('src', 'analysis/finetuning', 'analysis/forecasting'):\n",
    "    p = os.path.abspath(os.path.join(os.getcwd(), rel))\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# now imports that rely on those paths\n",
    "from utils import SequentialDeepONetDataset\n",
    "from helper import load_model_experiment, convert2dim, fit, compute_metrics_region, plot_field_region\n",
    "from forecasting_analysis import create_windows_forecasting_with_index\n",
    "from finetune import create_contiguous_adaptation_set, create_eval_set_after_contiguous_adaptation, freeze_for_new_station_adaptation, expand_lstm_input_dim_correct, mask_new_station, fine_tune_adapt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input sensor data: neutron monitor data \n",
    "input_sensor = np.load('data/neutron_data_22yrs.npy')\n",
    "\n",
    "# location\n",
    "trunk = np.load('data/grid_points_025.npy')\n",
    "\n",
    "# Normalize trunk input\n",
    "trunk[:, 0] = (trunk[:, 0] - np.min(trunk[:, 0])) / (np.max(trunk[:, 0]) - np.min(trunk[:, 0]))\n",
    "trunk[:, 1] = (trunk[:, 1] - np.min(trunk[:, 1])) / (np.max(trunk[:, 1]) - np.min(trunk[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e4d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# \n",
    "# base_dir = Path(\"data/DoseNumpy025/10m\")\n",
    "# \n",
    "# years = range(2001, 2024)  # 2001â€“2023 inclusive\n",
    "# \n",
    "# arrays = []\n",
    "# for year in years:\n",
    "#     print(f\"Loading data for year: {year}\")\n",
    "#     fname = base_dir / f\"dose_{year}_10m.npy\"\n",
    "#     arr = np.load(fname)          # shape e.g. (T_year, H, W) or (T_year, N_points)\n",
    "#     arrays.append(arr)\n",
    "# \n",
    "# # Concatenate along time axis (axis=0)\n",
    "# dose_all = np.concatenate(arrays, axis=0)\n",
    "# \n",
    "# print(\"Per-year shape:\", arrays[0].shape)\n",
    "# print(\"Combined shape:\", dose_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4429d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.load('data/DoseNumpy025/dose_2001_2023_10m.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc74074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([7641, 30, 12]) torch.Size([7641, 1038961])\n",
      "Validation set: torch.Size([365, 30, 12]) torch.Size([365, 1038961])\n",
      "Test set: torch.Size([365, 30, 12]) torch.Size([365, 1038961])\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range(\"2001-01-01\", \"2023-12-31\", freq=\"D\")\n",
    "\n",
    "W, H = 30, 0\n",
    "X_all, y_all, tgt_idx = create_windows_forecasting_with_index(input_sensor, output, W, H)\n",
    "tgt_dates = dates[tgt_idx]\n",
    "\n",
    "train_mask = (tgt_dates <= pd.Timestamp(\"2021-12-31\"))\n",
    "val_mask   = (tgt_dates >= pd.Timestamp(\"2022-01-01\")) & (tgt_dates <= pd.Timestamp(\"2022-12-31\"))\n",
    "test_mask  = (tgt_dates >= pd.Timestamp(\"2023-01-01\")) & (tgt_dates <= pd.Timestamp(\"2023-12-31\"))\n",
    "\n",
    "X_train, y_train = X_all[train_mask], y_all[train_mask]\n",
    "X_val,   y_val   = X_all[val_mask],   y_all[val_mask]\n",
    "X_test,  y_test  = X_all[test_mask],  y_all[test_mask]\n",
    "\n",
    "# check shapes\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# remove unused variables to free memory\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befd6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_input = MinMaxScaler()\n",
    "X_train_scaled = scaler_input.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val_scaled   = scaler_input.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "X_test_scaled  = scaler_input.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2801bf61",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit on ALL training pixels (flattened)\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# Transform sets\n",
    "y_train_scaled = scaler_target.fit_transform(y_train)[..., np.newaxis]\n",
    "y_val_scaled   = scaler_target.transform(y_val)[..., np.newaxis]\n",
    "y_test_scaled  = scaler_target.transform(y_test)[..., np.newaxis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
