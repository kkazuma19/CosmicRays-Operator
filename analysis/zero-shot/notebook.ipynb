{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compactly add project src and analysis/zero-shot to sys.path if not already present\n",
    "for rel in ('src', 'analysis/zero-shot', 'analysis/forecasting'):\n",
    "    p = os.path.abspath(os.path.join(os.getcwd(), rel))\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# now imports that rely on those paths\n",
    "from utils import create_sliding_windows, SequentialDeepONetDataset\n",
    "from helper import load_model_experiment, convert2dim, train_val_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Load model\n",
    "#------------------------------\n",
    "model_path = 'analysis/baseline/single_branch/lstm_window_30.pth'\n",
    "\n",
    "model = load_model_experiment(model_path).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e21cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Load test input function (unseen 2023 data)\n",
    "# Load test target (resolution 1 deg)\n",
    "#------------------------------\n",
    "input_sensor = np.load('data/neutron_data_22yrs.npy')\n",
    "\n",
    "# 1 degree target\n",
    "output_1deg = np.load('data/dose_array.npy')\n",
    "\n",
    "# 0.25 degree target\n",
    "output_025deg = np.load('data/DoseNumpy025/dose_2001_2023_0m.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window size\n",
    "window_size = 30\n",
    "\n",
    "from forecasting_analysis import create_windows_forecasting_with_index\n",
    "\n",
    "dates = pd.date_range(\"2001-01-01\", \"2023-12-31\", freq=\"D\")\n",
    "\n",
    "W, H = window_size, 0\n",
    "X_all_1, y_all_1, tgt_idx_1 = create_windows_forecasting_with_index(input_sensor, output_1deg, W, H)\n",
    "tgt_dates = dates[tgt_idx_1]\n",
    "\n",
    "X_all_025, y_all_025, tgt_idx_025 = create_windows_forecasting_with_index(input_sensor, output_025deg, W, H)\n",
    "\n",
    "train_mask = (tgt_dates <= pd.Timestamp(\"2021-12-31\"))\n",
    "test_mask  = (tgt_dates >= pd.Timestamp(\"2023-01-01\")) & (tgt_dates <= pd.Timestamp(\"2023-12-31\"))\n",
    "\n",
    "X_train, y_train_1 = X_all_1[train_mask], y_all_1[train_mask]\n",
    "X_test,  y_test_1  = X_all_1[test_mask],  y_all_1[test_mask]\n",
    "\n",
    "X_train, y_train_025 = X_all_025[train_mask], y_all_025[train_mask]\n",
    "X_test,  y_test_025  = X_all_025[test_mask],  y_all_025[test_mask]\n",
    "\n",
    "# check shapes\n",
    "print(\"Train set 1deg:\", X_train.shape, y_train_1.shape)\n",
    "print(\"Test set 1deg:\", X_test.shape, y_test_1.shape)\n",
    "print(\"Train set 025deg:\", X_train.shape, y_train_025.shape)\n",
    "print(\"Test set 025deg:\", X_test.shape, y_test_025.shape)\n",
    "\n",
    "# delete unused variables to free up memory\n",
    "del output_1deg\n",
    "del output_025deg\n",
    "del input_sensor\n",
    "del X_all_1\n",
    "del y_all_1\n",
    "del X_all_025\n",
    "del y_all_025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_input = MinMaxScaler()\n",
    "X_train_scaled = scaler_input.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "test_input_1 = scaler_input.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "test_input_025 = scaler_input.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# target data normalization (min-max scaling)\n",
    "scaler_target_1 = MinMaxScaler()\n",
    "scaler_target_025 = MinMaxScaler()\n",
    "\n",
    "train_target_1 = scaler_target_1.fit_transform(y_train_1)[..., np.newaxis]\n",
    "test_target_1 = scaler_target_1.transform(y_test_1)[..., np.newaxis]\n",
    "\n",
    "train_target_025 = scaler_target_025.fit_transform(y_train_025)[..., np.newaxis]\n",
    "test_target_025 = scaler_target_025.transform(y_test_025)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting keeping the consistency with training phase\n",
    "#train_input_1, train_target_1, val_input_1, val_target_1, test_input_1, test_target_1 = train_val_test_split(input_sensor, output_1deg)\n",
    "#train_input_025, train_target_025, val_input_025, val_target_025, test_input_025, test_target_025 = train_val_test_split(input_sensor, output_025deg)\n",
    "#\n",
    "## remove output_1deg and output_025deg from memory\n",
    "#del output_1deg\n",
    "#del output_025deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b911eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input scaler\n",
    "#scaler = MinMaxScaler()\n",
    "#\n",
    "## the input data is common for both 1 deg and 0.25 deg targets\n",
    "## so we fit the scaler only once using train_input_1\n",
    "#dummy = scaler.fit_transform(train_input_1)\n",
    "#test_input_1 = scaler.transform(test_input_1)\n",
    "#test_input_025 = scaler.transform(test_input_025)\n",
    "#\n",
    "## target data normalization (min-max scaling)\n",
    "#scaler_target_1 = MinMaxScaler()\n",
    "#train_target_1 = scaler_target_1.fit_transform(train_target_1)[..., np.newaxis]\n",
    "#test_target_1 = scaler_target_1.transform(test_target_1)[..., np.newaxis]\n",
    "#\n",
    "#scaler_target_025 = MinMaxScaler()\n",
    "#train_target_025 = scaler_target_025.fit_transform(train_target_025)[..., np.newaxis]\n",
    "#test_target_025 = scaler_target_025.transform(test_target_025)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0db19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location points for 1 degree target\n",
    "trunk_1deg = np.load('data/grid_points.npy')\n",
    "trunk_025deg = np.load('data/grid_points_025.npy')\n",
    "\n",
    "print('location range (1 deg):', np.min(trunk_1deg[:,0]), np.max(trunk_1deg[:,0]), np.min(trunk_1deg[:,1]), np.max(trunk_1deg[:,1]))\n",
    "print('location range (0.25 deg):', np.min(trunk_025deg[:,0]), np.max(trunk_025deg[:,0]), np.min(trunk_025deg[:,1]), np.max(trunk_025deg[:,1]))\n",
    "\n",
    "# Normalize trunk input\n",
    "trunk_1deg[:, 0] = (trunk_1deg[:, 0] - np.min(trunk_1deg[:, 0])) / (np.max(trunk_1deg[:, 0]) - np.min(trunk_1deg[:, 0]))\n",
    "trunk_1deg[:, 1] = (trunk_1deg[:, 1] - np.min(trunk_1deg[:, 1])) / (np.max(trunk_1deg[:, 1]) - np.min(trunk_1deg[:, 1]))\n",
    "\n",
    "trunk_025deg[:, 0] = (trunk_025deg[:, 0] - np.min(trunk_025deg[:, 0])) / (np.max(trunk_025deg[:, 0]) - np.min(trunk_025deg[:, 0]))\n",
    "trunk_025deg[:, 1] = (trunk_025deg[:, 1] - np.min(trunk_025deg[:, 1])) / (np.max(trunk_025deg[:, 1]) - np.min(trunk_025deg[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7461fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequences for the testing set\n",
    "#test_input_seq_1, test_target_seq_1 = create_sliding_windows(test_input_1, test_target_1, window_size=30)\n",
    "#\n",
    "#print('test_input_seq shape:', test_input_seq_1.shape)\n",
    "#print('test_target_seq shape:', test_target_seq_1.shape)\n",
    "#\n",
    "#test_input_seq_025, test_target_seq_025 = create_sliding_windows(test_input_025, test_target_025, window_size=30)\n",
    "#\n",
    "#print('test_input_seq_025 shape:', test_input_seq_025.shape)\n",
    "#print('test_target_seq_025 shape:', test_target_seq_025.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test set\n",
    "test_dataset_1 = SequentialDeepONetDataset(test_input_1, trunk_1deg, test_target_1)\n",
    "test_loader_1 = DataLoader(test_dataset_1, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset_025 = SequentialDeepONetDataset(test_input_025, trunk_025deg, test_target_025)\n",
    "test_loader_025 = DataLoader(test_dataset_025, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ae639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unused variables to free up memor\n",
    "del y_train_025\n",
    "del y_test_025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, data_loader, device, scaler_target):\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for branch_batch, trunk_batch, target_batch in data_loader:\n",
    "            branch_batch, trunk_batch, target_batch = (\n",
    "                branch_batch.to(device),\n",
    "                trunk_batch.to(device),\n",
    "                target_batch.to(device),\n",
    "            )\n",
    "            output = model(branch_batch, trunk_batch)\n",
    "            \n",
    "            all_outputs.append(output.cpu())\n",
    "            all_targets.append(target_batch.cpu())\n",
    "\n",
    "    # ...existing code...\n",
    "    # After loop:\n",
    "    outputs = torch.cat(all_outputs, dim=0)  # [N_test, ...]\n",
    "    targets = torch.cat(all_targets, dim=0)  # [N_test, ...]\n",
    "\n",
    "    # move to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "\n",
    "    # flatten to 2D (n_samples, n_features) for scaler\n",
    "    out_shape = outputs.shape\n",
    "    tgt_shape = targets.shape\n",
    "    outputs_flat = outputs.reshape(outputs.shape[0], -1)\n",
    "    targets_flat = targets.reshape(targets.shape[0], -1)\n",
    "\n",
    "    # inverse scale\n",
    "    outputs_flat = scaler_target.inverse_transform(outputs_flat)\n",
    "    targets_flat = scaler_target.inverse_transform(targets_flat)\n",
    "\n",
    "    # restore original shapes\n",
    "    outputs = outputs_flat.reshape(out_shape)\n",
    "    targets = targets_flat.reshape(tgt_shape)\n",
    "    # ...existing code...\n",
    "\n",
    "    \n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1deg, targets_1deg = fit(model, test_loader_1, device, scaler_target_1)\n",
    "print('predictions shape:', predictions_1deg.shape)\n",
    "print('targets shape:', targets_1deg.shape)\n",
    "\n",
    "predictions_025deg, targets_025deg = fit(model, test_loader_025, device, scaler_target_025)\n",
    "print('predictions shape:', predictions_025deg.shape)\n",
    "print('targets shape:', targets_025deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28abe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_grid_1, lat_grid_1, pred_img_1 = convert2dim(predictions_1deg)  # (N,H,W)\n",
    "_,        _,        targ_img_1 = convert2dim(targets_1deg)      # (N,H,W)\n",
    "\n",
    "lon_grid_025, lat_grid_025, pred_img_025 = convert2dim(predictions_025deg, grid_path='data/grid_points_025.npy')  # (N,H,W)\n",
    "_,          _,          targ_img_025 = convert2dim(targets_025deg, grid_path='data/grid_points_025.npy')      # (N,H,W)\n",
    "\n",
    "\n",
    "# print pred sizes\n",
    "print('1 deg pred_img shape:', pred_img_1.shape)\n",
    "print('0.25 deg pred_img shape:', pred_img_025.shape)\n",
    "\n",
    "print('1 deg targ_img shape:', targ_img_1.shape)\n",
    "print('0.25 deg targ_img shape:', targ_img_025.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a585be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def compute_metrics(pred_img, targ_img):\n",
    "    ''' \n",
    "    Compute and print evaluation metrics between predicted and target images.\n",
    "    Both inputs should be numpy arrays of shape (N, H, W), where N is the number of samples.\n",
    "    '''\n",
    "\n",
    "    pred_img = pred_img.astype(np.float64)\n",
    "    targ_img = targ_img.astype(np.float64)\n",
    "\n",
    "    N = pred_img.shape[0]\n",
    "    eps = 1e-12\n",
    "\n",
    "    # ---- Relative L2 (%) per-sample + mean ----\n",
    "    pf = pred_img.reshape(N, -1)\n",
    "    tf = targ_img.reshape(N, -1)\n",
    "    rel_l2_pct = 100.0 * np.linalg.norm(pf - tf, axis=1) / (np.linalg.norm(tf, axis=1) + eps)\n",
    "    print(\"Mean Relative L2 (%):\", rel_l2_pct.mean())\n",
    "\n",
    "    # ---- SSIM per-sample + mean (uses target’s per-sample dynamic range) ----\n",
    "    ssim_scores = np.empty(N, dtype=float)\n",
    "    for i in range(N):\n",
    "        dr = float(targ_img[i].max() - targ_img[i].min()) or 1.0\n",
    "        ssim_scores[i] = ssim(targ_img[i], pred_img[i], data_range=dr)\n",
    "    print(\"Mean SSIM:\", ssim_scores.mean())\n",
    "    \n",
    "    return rel_l2_pct, ssim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68836157",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_l2_1deg, ssim_1deg = compute_metrics(pred_img_1, targ_img_1)\n",
    "rel_l2_025deg, ssim_025deg = compute_metrics(pred_img_025, targ_img_025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaeca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_region(pred_img, targ_img, lon_grid, lat_grid, region_extent):\n",
    "    \"\"\"\n",
    "    Compute rel-L2 and SSIM restricted to a spatial subset.\n",
    "    region_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "    pred_img, targ_img: arrays of shape (N, H, W)\n",
    "    lon_grid, lat_grid: (H, W)\n",
    "    \"\"\"\n",
    "    lon_min, lon_max, lat_min, lat_max = region_extent\n",
    "\n",
    "    # Mask to select region\n",
    "    mask_lat = (lat_grid[:, 0] >= lat_min) & (lat_grid[:, 0] <= lat_max)\n",
    "    mask_lon = (lon_grid[0, :] >= lon_min) & (lon_grid[0, :] <= lon_max)\n",
    "\n",
    "    # Subset fields\n",
    "    pred_sub = pred_img[:, mask_lat, :][:, :, mask_lon]\n",
    "    targ_sub = targ_img[:, mask_lat, :][:, :, mask_lon]\n",
    "\n",
    "    # Flatten spatial dims\n",
    "    N = pred_sub.shape[0]\n",
    "    eps = 1e-12\n",
    "    pf = pred_sub.reshape(N, -1)\n",
    "    tf = targ_sub.reshape(N, -1)\n",
    "\n",
    "    # --- Relative L2 (%) ---\n",
    "    rel_l2_pct = 100.0 * np.linalg.norm(pf - tf, axis=1) / (np.linalg.norm(tf, axis=1) + eps)\n",
    "\n",
    "    # --- SSIM ---\n",
    "    ssim_scores = np.empty(N, dtype=float)\n",
    "    for i in range(N):\n",
    "        dr = float(targ_sub[i].max() - targ_sub[i].min()) or 1.0\n",
    "        ssim_scores[i] = ssim(targ_sub[i], pred_sub[i], data_range=dr)\n",
    "\n",
    "    print(f\"Region {region_extent}\")\n",
    "    print(\"Mean rel-L2 (%):\", rel_l2_pct.mean())\n",
    "    print(\"Mean SSIM:\", ssim_scores.mean())\n",
    "    \n",
    "    return rel_l2_pct, ssim_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target date Jan 01 2023 to Dec 31 2023\n",
    "target_date = pd.date_range(\"2023-01-01\", \"2023-12-31\", freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f056f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "# --- Compute 50th percentile and corresponding date ---\n",
    "rel_l2_1deg_50pct = np.percentile(rel_l2_1deg, 50)\n",
    "idx_50pct_1deg = np.argmin(np.abs(rel_l2_1deg - rel_l2_1deg_50pct))\n",
    "date_50pct_1deg = target_date[idx_50pct_1deg]\n",
    "print(\"Median L2 (1°):\", rel_l2_1deg_50pct)\n",
    "print(\"Date:\", date_50pct_1deg)\n",
    "\n",
    "# --- Create figure ---\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "gs = gridspec.GridSpec(\n",
    "    2, 4, figure=fig,\n",
    "    width_ratios=[10, 1, 1, 5],\n",
    "    height_ratios=[1, 1],\n",
    "    wspace=0.5, hspace=0.5\n",
    ")\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# =====================================================\n",
    "# Row 1: 1° data (top)\n",
    "# =====================================================\n",
    "ax1 = fig.add_subplot(gs[0, 0:3])\n",
    "ax1.set_ylabel('Rel L2 (%)', fontweight='bold', fontsize=fontsize)\n",
    "line1, = ax1.plot(target_date, rel_l2_1deg, color='tab:blue', linewidth=2)\n",
    "ax1.set_xlim([target_date[0], target_date[-1]])\n",
    "\n",
    "# Add yellow star marker for 50th percentile\n",
    "star1, = ax1.plot(date_50pct_1deg, rel_l2_1deg[idx_50pct_1deg],\n",
    "                  marker='*', color='yellow', markersize=14,\n",
    "                  markeredgecolor='black', label='50th percentile')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 3])\n",
    "ax2.scatter(rel_l2_1deg, ssim_1deg, color='purple', alpha=0.5)\n",
    "ax2.set_xlabel(\"Rel L2 (%)\", fontweight='bold', fontsize=fontsize)\n",
    "ax2.set_ylabel(\"SSIM\", fontweight='bold', fontsize=fontsize)\n",
    "\n",
    "# =====================================================\n",
    "# Row 2: 0.25° data (bottom)\n",
    "# =====================================================\n",
    "ax3 = fig.add_subplot(gs[1, 0:3])\n",
    "ax3.set_ylabel('Rel L2 (%)', fontweight='bold', fontsize=fontsize)\n",
    "line2, = ax3.plot(target_date, rel_l2_025deg, color='tab:orange', linewidth=2)\n",
    "ax3.set_xlim([target_date[0], target_date[-1]])\n",
    "\n",
    "# Add yellow star marker at same date (nearest match)\n",
    "idx_50pct_025deg = np.argmin(np.abs(target_date - date_50pct_1deg))\n",
    "star2, = ax3.plot(date_50pct_1deg, rel_l2_025deg[idx_50pct_025deg],\n",
    "                  marker='*', color='yellow', markersize=14,\n",
    "                  markeredgecolor='black', label='50th percentile')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 3])\n",
    "ax4.scatter(rel_l2_025deg, ssim_025deg, color='green', alpha=0.5)\n",
    "ax4.set_xlabel(\"Rel L2 (%)\", fontweight='bold', fontsize=fontsize)\n",
    "ax4.set_ylabel(\"SSIM\", fontweight='bold', fontsize=fontsize)\n",
    "\n",
    "# =====================================================\n",
    "# Formatting\n",
    "# =====================================================\n",
    "# Tick formatting\n",
    "for ax in [ax1, ax3]:\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "for ax in [ax2, ax4]:\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Make all tick labels bold\n",
    "#for ax in [ax1, ax2, ax3, ax4]:\n",
    "#    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "#        label.set_fontweight('bold')\n",
    "\n",
    "# Align y-labels in first column\n",
    "ax1.yaxis.set_label_coords(-0.07, 0.5)\n",
    "ax3.yaxis.set_label_coords(-0.07, 0.5)\n",
    "\n",
    "\n",
    "# Filter out any automatically generated artists\n",
    "handles = [h for h in [line2, star2] if not h.get_label().startswith('_')]\n",
    "\n",
    "legend2 = ax3.legend(handles=handles,\n",
    "                     frameon=True,\n",
    "                     edgecolor='black',\n",
    "                     facecolor='none',\n",
    "                     fontsize=10,\n",
    "                     loc='upper right')\n",
    "\n",
    "# Make legend text bold and border a bit thicker\n",
    "for text in legend2.get_texts():\n",
    "    text.set_fontweight('bold')\n",
    "legend2.get_frame().set_linewidth(1.2)\n",
    "legend2.get_frame().set_boxstyle('Square')\n",
    "\n",
    "plt.savefig('analysis/zero-shot/relL2_ssim_timeseries.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting setting\n",
    "Lon025 = lon_grid_025\n",
    "Lat025 = lat_grid_025\n",
    "field025 = pred_img_025\n",
    "error025 = np.abs(targ_img_025 - pred_img_025)\n",
    "\n",
    "# 1 degree\n",
    "Lon1 = lon_grid_1\n",
    "Lat1 = lat_grid_1\n",
    "field1 = pred_img_1\n",
    "error1 = np.abs(targ_img_1 - pred_img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import plot_field_region\n",
    "import cmocean\n",
    "cmap_seq = cmocean.cm.thermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day index\n",
    "day = idx_50pct_1deg\n",
    "\n",
    "\n",
    "plot_field_region(\n",
    "    Lon025, Lat025, field025, i=day,\n",
    "    title=f\"Effective Dose Rate Prediction (0.25°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Effective Dose Rate (µSv/h)\",\n",
    "    region_extent=[-180, 180, -90, 90],\n",
    "    vmin=0.025, vmax=0.040,\n",
    "    tick_step=(60, 30),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 20),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_025deg_global.png'\n",
    ")\n",
    "plt.gcf().set_size_inches(6, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9eefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_field_region(\n",
    "    Lon1, Lat1, field1, i=day,\n",
    "    #title=f\"Effective Dose Rate Prediction (1°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Effective Dose Rate (µSv/h)\",\n",
    "    region_extent=[-180, 180, -90, 90],\n",
    "    vmin=0.025, vmax=0.040,\n",
    "    tick_step=(60, 30),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 20),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_1deg_global.png'\n",
    ")\n",
    "plt.gcf().set_size_inches(6, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_extent = [-140, -40, 0, 60]  # e.g., South Atlantic region\n",
    "\n",
    "# compute metrics in the specified region\n",
    "rel_l2_025, ssim_score_025 = compute_metrics_region(\n",
    "    pred_img_025, targ_img_025, lon_grid_025, lat_grid_025, region_extent\n",
    ")\n",
    "\n",
    "print(\"Rel L2 (%) in region:\", rel_l2_025[day])\n",
    "print(\"SSIM in region:\", ssim_score_025[day])\n",
    "\n",
    "# plot in the specified region\n",
    "plot_field_region(\n",
    "    Lon025, Lat025, field025, i=day,\n",
    "    #title=f\"Effective Dose Rate Prediction (0.25°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Effective Dose Rate (µSv/h)\",\n",
    "    region_extent=region_extent,\n",
    "    vmin=0.025, vmax=0.040,\n",
    "    tick_step=(20, 20),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 10),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_025deg_region.png'\n",
    ")\n",
    "plt.gcf().set_size_inches(6, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0830a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics in the specified region\n",
    "rel_l2_1, ssim_score_1 = compute_metrics_region(\n",
    "    pred_img_1, targ_img_1, lon_grid_1, lat_grid_1, region_extent\n",
    ")\n",
    "\n",
    "print(\"Rel L2 (%) in region:\", rel_l2_1[day])\n",
    "print(\"SSIM in region:\", ssim_score_1[day])\n",
    "\n",
    "# plot in the specified region\n",
    "plot_field_region(\n",
    "    Lon1, Lat1, field1, i=day,\n",
    "    #title=f\"Effective Dose Rate Prediction (1°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Effective Dose Rate (µSv/h)\",\n",
    "    region_extent=region_extent,\n",
    "    vmin=0.025, vmax=0.040,\n",
    "    tick_step=(20, 20),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 10),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_1deg_region.png'\n",
    ")\n",
    "plt.gcf().set_size_inches(6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_field_region(\n",
    "    Lon025, Lat025, error025, i=day,\n",
    "    title=f\"Prediction Error on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Effective Dose Rate (µSv/h)\",\n",
    "    region_extent=[-180, 180, -90, 90],\n",
    "    #vmin=0.025, vmax=0.040,\n",
    "    tick_step=(60, 30),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 20),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet'\n",
    ")\n",
    "plt.gcf().set_size_inches(6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bafb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in the specified region\n",
    "plot_field_region(\n",
    "    Lon025, Lat025, error025, i=day,\n",
    "    #title=f\"Prediction Error (0.25°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Error Magnitude (µSv/h)\",\n",
    "    region_extent=region_extent,\n",
    "    #vmin=0.025, vmax=0.040,\n",
    "    tick_step=(20, 20),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 10),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_error_025deg_region.png'\n",
    ")\n",
    "#plt.gcf().set_size_inches(6, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in the specified region\n",
    "plot_field_region(\n",
    "    Lon1, Lat1, error1, i=day,\n",
    "    #title=f\"Prediction Error (1°) on {pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')}\",\n",
    "    units_label=\"Error Magnitude (µSv/h)\",\n",
    "    region_extent=region_extent,\n",
    "    #vmin=0.025, vmax=0.040,\n",
    "    tick_step=(20, 20),\n",
    "    add_contour=True, contour_levels=np.linspace(0.025, 0.040, 10),\n",
    "    mark_equator_meridian=False,\n",
    "    cmap= 'jet',\n",
    "    savepath='analysis/zero-shot/prediction_error_1deg_region.png'\n",
    ")\n",
    "#plt.gcf().set_size_inches(6, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea600298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean + std (1 degree)\n",
    "print(\"Rel L2 (%) in region:\", rel_l2_1.mean(), \"+/-\", rel_l2_1.std())\n",
    "print(\"SSIM in region:\", ssim_score_1.mean(), \"+/-\", ssim_score_1.std())\n",
    "\n",
    "# mean + std (0.25 degree)\n",
    "print(\"Rel L2 (%) in region:\", rel_l2_025.mean(), \"+/-\", rel_l2_025.std())\n",
    "print(\"SSIM in region:\", ssim_score_025.mean(), \"+/-\", ssim_score_025.std())\n",
    "\n",
    "# daily \n",
    "print(\"Daily Rel L2 (%) in region (1°):\", rel_l2_1[day])\n",
    "print(\"Daily SSIM in region (1°):\", ssim_score_1[day])\n",
    "\n",
    "print(\"Daily Rel L2 (%) in region (0.25°):\", rel_l2_025[day])\n",
    "print(\"Daily SSIM in region (0.25°):\", ssim_score_025[day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "# Metric values (mean ± std where available)\n",
    "# ===============================\n",
    "# --- Global (1-year mean) ---\n",
    "rel_l2_global_1,  std_l2_global_1  = rel_l2_1deg.mean(), rel_l2_1deg.std()\n",
    "rel_l2_global_025, std_l2_global_025 = rel_l2_025deg.mean(), rel_l2_025deg.std()\n",
    "ssim_global_1,  std_ssim_global_1  = ssim_1deg.mean(), ssim_1deg.std()\n",
    "ssim_global_025, std_ssim_global_025 = ssim_025deg.mean(), ssim_025deg.std()\n",
    "\n",
    "# --- Regional (1-year mean) ---\n",
    "rel_l2_regional_1,  std_l2_regional_1  = rel_l2_1.mean(), rel_l2_1.std()\n",
    "rel_l2_regional_025, std_l2_regional_025 = rel_l2_025.mean(), rel_l2_025.std()\n",
    "ssim_regional_1,  std_ssim_regional_1  = ssim_score_1.mean(), ssim_score_1.std()\n",
    "ssim_regional_025, std_ssim_regional_025 = ssim_score_025.mean(), ssim_score_025.std()\n",
    "\n",
    "# --- Regional (specific day) ---\n",
    "rel_l2_local_1 = rel_l2_1[day]\n",
    "rel_l2_local_025 = rel_l2_025[day]\n",
    "ssim_local_1 = ssim_score_1[day]\n",
    "ssim_local_025 = ssim_score_025[day]\n",
    "\n",
    "# ===============================\n",
    "# Plot settings\n",
    "# ===============================\n",
    "labels = ['Global (2023)', 'Regional (2023)', f\"Regional ({pd.to_datetime(target_date[day]).strftime('%Y-%m-%d')})\"]\n",
    "x = np.arange(len(labels))\n",
    "bar_width = 0.3\n",
    "gap = 0.05\n",
    "\n",
    "# --- Improved color palette (scientific & colorblind safe) ---\n",
    "color_1deg = '#4477AA'   # muted blue\n",
    "color_025deg = '#CC6677' # warm salmon\n",
    "hatch_style = '///'      # hatch pattern for Regional (Day)\n",
    "\n",
    "# Create vertical subplots (2 rows, 1 column)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(7, 8), sharex=True)\n",
    "\n",
    "# -------------------------------\n",
    "# (a) Relative L2 Error (%)\n",
    "# -------------------------------\n",
    "vals_1deg = [rel_l2_global_1, rel_l2_regional_1, rel_l2_local_1]\n",
    "vals_025deg = [rel_l2_global_025, rel_l2_regional_025, rel_l2_local_025]\n",
    "std_1deg = [std_l2_global_1, std_l2_regional_1, 0]\n",
    "std_025deg = [std_l2_global_025, std_l2_regional_025, 0]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    hatch = hatch_style if i == 2 else None\n",
    "    axs[0].bar(x[i] - (bar_width/2 + gap/2), vals_1deg[i],\n",
    "               width=bar_width, color=color_1deg, alpha=0.9, hatch=hatch,\n",
    "               edgecolor='black', linewidth=0.6,\n",
    "               yerr=None if std_1deg[i] == 0 else std_1deg[i],\n",
    "               capsize=3 if std_1deg[i] != 0 else 0)\n",
    "    axs[0].bar(x[i] + (bar_width/2 + gap/2), vals_025deg[i],\n",
    "               width=bar_width, color=color_025deg, alpha=0.9, hatch=hatch,\n",
    "               edgecolor='black', linewidth=0.6,\n",
    "               yerr=None if std_025deg[i] == 0 else std_025deg[i],\n",
    "               capsize=3 if std_025deg[i] != 0 else 0)\n",
    "\n",
    "axs[0].set_ylabel('Relative L2 error (%)', fontsize=18)\n",
    "axs[0].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "axs[0].legend(['1°', '0.25°'], frameon=False, loc='upper right', fontsize=12)\n",
    "axs[0].set_ylim(0, 0.18)\n",
    "axs[0].set_title('Relative L2 Error', fontsize=20, pad=6)\n",
    "axs[0].set_xticks(x)\n",
    "axs[0].set_xticklabels(labels, fontsize=15, rotation=10)\n",
    "\n",
    "# -------------------------------\n",
    "# (b) Structural Similarity (SSIM)\n",
    "# -------------------------------\n",
    "vals_1deg = [ssim_global_1, ssim_regional_1, ssim_local_1]\n",
    "vals_025deg = [ssim_global_025, ssim_regional_025, ssim_local_025]\n",
    "std_1deg = [std_ssim_global_1, std_ssim_regional_1, 0]\n",
    "std_025deg = [std_ssim_global_025, std_ssim_regional_025, 0]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    hatch = hatch_style if i == 2 else None\n",
    "    axs[1].bar(x[i] - (bar_width/2 + gap/2), vals_1deg[i],\n",
    "               width=bar_width, color=color_1deg, alpha=0.9, hatch=hatch,\n",
    "               edgecolor='black', linewidth=0.6,\n",
    "               yerr=None if std_1deg[i] == 0 else std_1deg[i],\n",
    "               capsize=3 if std_1deg[i] != 0 else 0)\n",
    "    axs[1].bar(x[i] + (bar_width/2 + gap/2), vals_025deg[i],\n",
    "               width=bar_width, color=color_025deg, alpha=0.9, hatch=hatch,\n",
    "               edgecolor='black', linewidth=0.6,\n",
    "               yerr=None if std_025deg[i] == 0 else std_025deg[i],\n",
    "               capsize=3 if std_025deg[i] != 0 else 0)\n",
    "\n",
    "axs[1].set_ylabel('SSIM', fontsize=18)\n",
    "axs[1].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "axs[1].set_ylim(0.997, 1.0000)\n",
    "axs[1].set_title('Structural Similarity', fontsize=20, pad=6)\n",
    "axs[1].set_xticks(x)\n",
    "axs[1].set_xticklabels(labels, fontsize=15)\n",
    "\n",
    "# -------------------------------\n",
    "# Final formatting\n",
    "# -------------------------------\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='both', labelsize=13)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "plt.tight_layout(h_pad=2.2)\n",
    "plt.savefig('analysis/zero-shot/summary_metrics.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86684c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
