{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d13f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d5bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# compactly add project src and analysis/zero-shot to sys.path if not already present\n",
    "for rel in ('src', 'analysis/zero-shot'):\n",
    "    p = os.path.abspath(os.path.join(os.getcwd(), rel))\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "# now imports that rely on those paths\n",
    "from utils import create_sliding_windows, SequentialDeepONetDataset\n",
    "from helper import load_model_experiment, convert2dim, train_val_test_split, plot_global_field_cartopy, plot_global_field_box\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019d5959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/bcnx/kazumak2/CosmicRays-Operator/analysis/zero-shot/helper.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from single_branch/lstm_window_30.pth\n",
      "SequentialDeepONet(\n",
      "  (branch_net): LSTM(\n",
      "    (lstm): LSTM(12, 128, num_layers=4, batch_first=True)\n",
      "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (trunk_net): FCN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# Load model\n",
    "#------------------------------\n",
    "model_path = 'single_branch/lstm_window_30.pth'\n",
    "\n",
    "model = load_model_experiment(model_path).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e21cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# Load test input function (unseen 2023 data)\n",
    "# Load test target (resolution 1 deg)\n",
    "#------------------------------\n",
    "input_sensor = np.load('data/neutron_data_22yrs.npy')\n",
    "\n",
    "# 1 degree target (scaled)\n",
    "output_1deg = np.load('data/dose_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8631aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape: (4017, 12)\n",
      "Validation input shape: (4018, 12)\n",
      "Test input shape: (365, 12)\n"
     ]
    }
   ],
   "source": [
    "# data splitting keeping the consistency with training phase\n",
    "train_input, train_target, val_input, val_target, test_input, test_target = train_val_test_split(input_sensor, output_1deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b911eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "dummy = scaler.fit_transform(train_input)\n",
    "test_input = scaler.transform(test_input)\n",
    "\n",
    "# target data normalization (min-max scaling)\n",
    "scaler_target = MinMaxScaler()\n",
    "train_target = scaler_target.fit_transform(train_target)[..., np.newaxis]\n",
    "test_target = scaler_target.transform(test_target)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0db19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location range (1 deg): -90.0 90.0 -180.0 180.0\n"
     ]
    }
   ],
   "source": [
    "# location points for 1 degree target\n",
    "trunk_1deg = np.load('data/grid_points.npy')\n",
    "\n",
    "print('location range (1 deg):', np.min(trunk_1deg[:,0]), np.max(trunk_1deg[:,0]), np.min(trunk_1deg[:,1]), np.max(trunk_1deg[:,1]))\n",
    "\n",
    "# Normalize trunk input\n",
    "trunk_1deg[:, 0] = (trunk_1deg[:, 0] - np.min(trunk_1deg[:, 0])) / (np.max(trunk_1deg[:, 0]) - np.min(trunk_1deg[:, 0]))\n",
    "trunk_1deg[:, 1] = (trunk_1deg[:, 1] - np.min(trunk_1deg[:, 1])) / (np.max(trunk_1deg[:, 1]) - np.min(trunk_1deg[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7461fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input_seq shape: torch.Size([336, 30, 12])\n",
      "test_target_seq shape: torch.Size([336, 65341, 1])\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences for the testing set\n",
    "test_input_seq, test_target_seq = create_sliding_windows(test_input, test_target, window_size=30)\n",
    "print('test_input_seq shape:', test_input_seq.shape)\n",
    "print('test_target_seq shape:', test_target_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c76b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test set\n",
    "test_dataset = SequentialDeepONetDataset(test_input_seq, trunk_1deg, test_target_seq)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0bb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, data_loader, device):\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for branch_batch, trunk_batch, target_batch in data_loader:\n",
    "            branch_batch, trunk_batch, target_batch = (\n",
    "                branch_batch.to(device),\n",
    "                trunk_batch.to(device),\n",
    "                target_batch.to(device),\n",
    "            )\n",
    "            output = model(branch_batch, trunk_batch)\n",
    "            \n",
    "            all_outputs.append(output.cpu())\n",
    "            all_targets.append(target_batch.cpu())\n",
    "\n",
    "    # ...existing code...\n",
    "    # After loop:\n",
    "    outputs = torch.cat(all_outputs, dim=0)  # [N_test, ...]\n",
    "    targets = torch.cat(all_targets, dim=0)  # [N_test, ...]\n",
    "\n",
    "    # move to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "\n",
    "    # flatten to 2D (n_samples, n_features) for scaler\n",
    "    out_shape = outputs.shape\n",
    "    tgt_shape = targets.shape\n",
    "    outputs_flat = outputs.reshape(outputs.shape[0], -1)\n",
    "    targets_flat = targets.reshape(targets.shape[0], -1)\n",
    "\n",
    "    # inverse scale\n",
    "    outputs_flat = scaler_target.inverse_transform(outputs_flat)\n",
    "    targets_flat = scaler_target.inverse_transform(targets_flat)\n",
    "\n",
    "    # restore original shapes\n",
    "    outputs = outputs_flat.reshape(out_shape)\n",
    "    targets = targets_flat.reshape(tgt_shape)\n",
    "    # ...existing code...\n",
    "\n",
    "    \n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5517fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (336, 65341, 1)\n",
      "targets shape: (336, 65341, 1)\n"
     ]
    }
   ],
   "source": [
    "predictions_1deg, targets_1deg = fit(model, test_loader, device)\n",
    "print('predictions shape:', predictions_1deg.shape)\n",
    "print('targets shape:', targets_1deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28abe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_grid, lat_grid, pred_img = convert2dim(predictions_1deg)  # (N,H,W)\n",
    "_,        _,        targ_img = convert2dim(targets_1deg)      # (N,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a585be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rel L2 (%): 0.11222334735855127\n",
      "Global rel L2 (%): 0.11618928691362994\n",
      "Mean SSIM: 0.9993264089659769\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "pred_img = pred_img.astype(np.float64)\n",
    "targ_img = targ_img.astype(np.float64)\n",
    "\n",
    "N = pred_img.shape[0]\n",
    "eps = 1e-12\n",
    "\n",
    "# ---- Relative L2 (%) per-sample + mean ----\n",
    "pf = pred_img.reshape(N, -1)\n",
    "tf = targ_img.reshape(N, -1)\n",
    "rel_l2 = np.linalg.norm(pf - tf, axis=1) / np.maximum(np.linalg.norm(tf, axis=1), eps)\n",
    "rel_l2_pct = 100.0 * rel_l2\n",
    "print(\"Mean rel L2 (%):\", rel_l2_pct.mean())\n",
    "\n",
    "# (optional) global relative L2 (%)\n",
    "global_rel_l2_pct = 100.0 * np.linalg.norm(pf - tf) / (np.linalg.norm(tf) + eps)\n",
    "print(\"Global rel L2 (%):\", global_rel_l2_pct)\n",
    "\n",
    "# ---- SSIM per-sample + mean (uses target’s per-sample dynamic range) ----\n",
    "ssim_scores = np.empty(N, dtype=float)\n",
    "for i in range(N):\n",
    "    dr = float(targ_img[i].max() - targ_img[i].min()) or 1.0\n",
    "    ssim_scores[i] = ssim(targ_img[i], pred_img[i], data_range=dr)\n",
    "print(\"Mean SSIM:\", ssim_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9156f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean\n",
    "cmap_seq = cmocean.cm.thermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed5328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atlantic-centered box (0°)\n",
    "plot_global_field_box(\n",
    "    lon_grid, lat_grid, pred_img, i=10,\n",
    "    title=\"Prediction (orig units)\",\n",
    "    units_label=\"Effective Dose Rate (μSv/h)\",\n",
    "    cmap=cmap_seq, central_longitude=0,\n",
    "    savepath=\"analysis/zero-shot/pred_box_0.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (/u/kazumak2/.conda/envs/pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
